{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST\n",
    "Here we load the dataset and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251dd46caf764ba19d7f77ee6de4843d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ae53dd5a2841aca6752b3412ae04a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aab40b8033d4511811ae59636ec5b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f41ac622f84565b960d351b8fa021d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yannetinterian/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1595629449223/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_ds = datasets.MNIST('data', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "test_ds = datasets.MNIST('data', train=False, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "#batch_size = 5 # for testing\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = iter(train_loader)\n",
    "x, y = next(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking are images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, title=None):\n",
    "    plt.imshow(img, interpolation='none', cmap=\"gray\")\n",
    "    if title is not None: plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first from torch to numpy\n",
    "X = x.numpy(); Y = y.numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(X[0][0], Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0][0][:4][:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the number of neurons in the hidden unit\n",
    "def get_model(M = 300):\n",
    "    net = nn.Sequential(nn.Linear(28*28, M),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(M, 10))\n",
    "    return net #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, num_epochs, model, optimizer):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            batch = images.shape[0] # size of the batch\n",
    "            # Convert torch tensor to Variable, change shape of the input\n",
    "            images = images.view(-1, 28*28) #.cuda()\n",
    "        \n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total += batch\n",
    "            sum_loss += batch * loss.item()\n",
    "                \n",
    "        train_loss = sum_loss/total\n",
    "        print('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, train_loss))\n",
    "        val_acc, val_loss = model_accuracy_loss(model, test_loader)\n",
    "        print('Epoch [%d/%d], Valid Accuracy: %.4f, Valid Loss: %.4f' %(epoch+1, num_epochs, val_acc, val_loss))\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy_loss(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 28*28)  #.cuda()\n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        sum_loss += labels.size(0)*loss.item()\n",
    "        total += labels.size(0)\n",
    "        correct += pred.eq(labels.data).sum().item()\n",
    "    return 100 * correct / total, sum_loss/ total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.04, 2.3412227783203123)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = get_model()\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "model_accuracy_loss(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 0.2512\n",
      "Epoch [1/2], Valid Accuracy: 94.2700, Valid Loss: 0.2195\n",
      "Epoch [2/2], Loss: 0.2363\n",
      "Epoch [2/2], Valid Accuracy: 93.7200, Valid Loss: 0.2751\n"
     ]
    }
   ],
   "source": [
    "val_acc, val_loss, train_loss = train_model(train_loader, test_loader, num_epochs=2, model=net, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with L2 regularization\n",
    "To add L2 regularization use the `weight_decay` argument on the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_v2(M = 300, p=0):\n",
    "    modules = []\n",
    "    modules.append(nn.Linear(28*28, M))\n",
    "    modules.append(nn.ReLU())\n",
    "    if p > 0:\n",
    "        modules.append(nn.Dropout(p))\n",
    "    modules.append(nn.Linear(M, 10))\n",
    "    return nn.Sequential(*modules) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_model_v2(M = 300, p=0.1)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Loss: 0.7422\n",
      "Epoch [1/4], Loss: 0.5880\n",
      "Epoch [1/4], Loss: 0.5494\n",
      "Epoch [1/4], Loss: 0.5195\n",
      "Epoch [1/4], Loss: 0.5020\n",
      "Epoch [1/4], Loss: 0.4917\n",
      "Epoch [1/4], Loss: 0.4791\n",
      "Epoch [1/4], Loss: 0.4672\n",
      "Epoch [1/4], Loss: 0.4643\n",
      "Epoch [1/4], Loss: 0.4618\n",
      "Epoch [1/4], Loss: 0.4566\n",
      "Epoch [1/4], Loss: 0.4517\n",
      "Epoch [1/4], Loss: 0.4441\n",
      "Epoch [1/4], Loss: 0.4386\n",
      "Epoch [1/4], Loss: 0.4337\n",
      "Epoch [1/4], Loss: 0.4328\n",
      "Epoch [1/4], Loss: 0.4282\n",
      "Epoch [1/4], Loss: 0.4277\n",
      "Epoch [1/4], Loss: 0.4256\n",
      "Epoch [1/4], Valid Accuracy: 91.4200, Valid Loss: 0.3112\n",
      "Epoch [2/4], Loss: 0.4166\n",
      "Epoch [2/4], Loss: 0.4097\n",
      "Epoch [2/4], Loss: 0.4042\n",
      "Epoch [2/4], Loss: 0.3971\n",
      "Epoch [2/4], Loss: 0.3909\n",
      "Epoch [2/4], Loss: 0.3853\n",
      "Epoch [2/4], Loss: 0.3809\n",
      "Epoch [2/4], Loss: 0.3765\n",
      "Epoch [2/4], Loss: 0.3742\n",
      "Epoch [2/4], Loss: 0.3706\n",
      "Epoch [2/4], Loss: 0.3658\n",
      "Epoch [2/4], Loss: 0.3628\n",
      "Epoch [2/4], Loss: 0.3604\n",
      "Epoch [2/4], Loss: 0.3575\n",
      "Epoch [2/4], Loss: 0.3552\n",
      "Epoch [2/4], Loss: 0.3520\n",
      "Epoch [2/4], Loss: 0.3490\n",
      "Epoch [2/4], Loss: 0.3467\n",
      "Epoch [2/4], Loss: 0.3456\n",
      "Epoch [2/4], Valid Accuracy: 92.3400, Valid Loss: 0.3000\n",
      "Epoch [3/4], Loss: 0.3421\n",
      "Epoch [3/4], Loss: 0.3392\n",
      "Epoch [3/4], Loss: 0.3363\n",
      "Epoch [3/4], Loss: 0.3345\n",
      "Epoch [3/4], Loss: 0.3328\n",
      "Epoch [3/4], Loss: 0.3306\n",
      "Epoch [3/4], Loss: 0.3301\n",
      "Epoch [3/4], Loss: 0.3289\n",
      "Epoch [3/4], Loss: 0.3273\n",
      "Epoch [3/4], Loss: 0.3262\n",
      "Epoch [3/4], Loss: 0.3249\n",
      "Epoch [3/4], Loss: 0.3243\n",
      "Epoch [3/4], Loss: 0.3229\n",
      "Epoch [3/4], Loss: 0.3217\n",
      "Epoch [3/4], Loss: 0.3209\n",
      "Epoch [3/4], Loss: 0.3194\n",
      "Epoch [3/4], Loss: 0.3178\n",
      "Epoch [3/4], Loss: 0.3166\n",
      "Epoch [3/4], Loss: 0.3159\n",
      "Epoch [3/4], Valid Accuracy: 93.9900, Valid Loss: 0.2542\n",
      "Epoch [4/4], Loss: 0.3148\n",
      "Epoch [4/4], Loss: 0.3137\n",
      "Epoch [4/4], Loss: 0.3122\n",
      "Epoch [4/4], Loss: 0.3111\n",
      "Epoch [4/4], Loss: 0.3097\n",
      "Epoch [4/4], Loss: 0.3092\n",
      "Epoch [4/4], Loss: 0.3082\n",
      "Epoch [4/4], Loss: 0.3071\n",
      "Epoch [4/4], Loss: 0.3069\n",
      "Epoch [4/4], Loss: 0.3064\n",
      "Epoch [4/4], Loss: 0.3049\n",
      "Epoch [4/4], Loss: 0.3046\n",
      "Epoch [4/4], Loss: 0.3042\n",
      "Epoch [4/4], Loss: 0.3033\n",
      "Epoch [4/4], Loss: 0.3028\n",
      "Epoch [4/4], Loss: 0.3026\n",
      "Epoch [4/4], Loss: 0.3022\n",
      "Epoch [4/4], Loss: 0.3012\n",
      "Epoch [4/4], Loss: 0.3011\n",
      "Epoch [4/4], Valid Accuracy: 93.5500, Valid Loss: 0.3018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.55, 0.301843672710564, 0.3010863176873885)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_loader, test_loader, num_epochs=4, model=net, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
