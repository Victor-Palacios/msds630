{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)\n",
    "\n",
    "Named Entity Recognition (NER) is an important  task in natural language processing. In this assignment you will implement a neural network model for NER.  In particular you will implement an approach called Sliding Window Neural Network. The dataset is composed of sentences. The dataframe already has each words parsed in one column and the corresponding label (entity) in the second column. We will build a \"window\" model, the idea on the window model is to use 5-word window to predict the name entity of the middle word. Here is the first observation in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/Genia4ERtask1.iob2\", sep=\"\\t\", header=None, names=[\"word\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IL-2</td>\n",
       "      <td>B-DNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gene</td>\n",
       "      <td>I-DNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>expression</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NF-kappa</td>\n",
       "      <td>B-protein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word      label\n",
       "0        IL-2      B-DNA\n",
       "1        gene      I-DNA\n",
       "2  expression          O\n",
       "3         and          O\n",
       "4    NF-kappa  B-protein"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_data = pd.read_csv(\"data/tiny.ner.train\", sep=\"\\t\", header=None, names=[\"word\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second observation is the 5 words starting with 'gene' and the label is the entity for the word 'and'. We have 5 features (categorical variables) which are words. We will use a word embedding to represent each value of the categorical features. For each observation, we concatenate the values of the 5 word embeddings for that observation. The vector of concatenated embeddings is feeded to a linear layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394040"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = int(data.shape[0]*0.8)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data.iloc[:N,].copy()\n",
    "valid_df = data.iloc[N:,].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((394040, 2), (98511, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word and label to index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = label_encoding(train_df[\"word\"].values)\n",
    "label2index = label_encoding(train_df[\"label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-DNA': 0,\n",
       " 'B-RNA': 1,\n",
       " 'B-cell_line': 2,\n",
       " 'B-cell_type': 3,\n",
       " 'B-protein': 4,\n",
       " 'I-DNA': 5,\n",
       " 'I-RNA': 6,\n",
       " 'I-cell_line': 7,\n",
       " 'I-cell_type': 8,\n",
       " 'I-protein': 9,\n",
       " 'O': 10}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_vocab2index = label_encoding(tiny_data[\"word\"].values)\n",
    "tiny_label2index = label_encoding(tiny_data[\"label\"].values)\n",
    "tiny_data_enc = dataset_encoding(tiny_data, tiny_vocab2index, tiny_label2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = np.array([17, 53, 31, 25, 44, 41, 32,  0, 11,  1])\n",
    "assert(np.array_equal(tiny_data_enc.iloc[30:40].word.values, actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_ds = NERDataset(tiny_data_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tiny_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11, 30, 26, 18, 13]), 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = tiny_ds[0]\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = tiny_ds[0]\n",
    "assert(np.array_equal(x, np.array([11, 30, 26, 18, 13])))\n",
    "assert(y == 6)\n",
    "assert(len(tiny_ds) == 93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding datasets\n",
    "train_df_enc = dataset_encoding(train_df, vocab2index, label2index)\n",
    "valid_df_enc = dataset_encoding(valid_df, vocab2index, label2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating datasets\n",
    "train_ds =  NERDataset(train_df_enc)\n",
    "valid_ds = NERDataset(valid_df_enc)\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 10000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  0.756 val loss 0.406 and accuracy 0.877\n",
      "train loss  0.319 val loss 0.326 and accuracy 0.899\n",
      "train loss  0.251 val loss 0.302 and accuracy 0.905\n",
      "train loss  0.217 val loss 0.296 and accuracy 0.908\n",
      "train loss  0.196 val loss 0.297 and accuracy 0.908\n",
      "train loss  0.181 val loss 0.287 and accuracy 0.911\n",
      "train loss  0.170 val loss 0.316 and accuracy 0.906\n",
      "train loss  0.162 val loss 0.312 and accuracy 0.907\n",
      "train loss  0.157 val loss 0.317 and accuracy 0.908\n",
      "train loss  0.151 val loss 0.306 and accuracy 0.908\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab2index)+1\n",
    "n_class = len(label2index)\n",
    "emb_size = 100\n",
    "\n",
    "model = NERModel(vocab_size, n_class, emb_size)\n",
    "optimizer = get_optimizer(model, lr = 0.01, wd = 1e-5)\n",
    "train_model(model, optimizer, train_dl, valid_dl, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  0.134 val loss 0.294 and accuracy 0.912\n",
      "train loss  0.129 val loss 0.297 and accuracy 0.911\n",
      "train loss  0.126 val loss 0.298 and accuracy 0.911\n",
      "train loss  0.125 val loss 0.299 and accuracy 0.911\n",
      "train loss  0.123 val loss 0.303 and accuracy 0.910\n",
      "train loss  0.122 val loss 0.304 and accuracy 0.910\n",
      "train loss  0.121 val loss 0.304 and accuracy 0.910\n",
      "train loss  0.120 val loss 0.307 and accuracy 0.910\n",
      "train loss  0.119 val loss 0.306 and accuracy 0.910\n",
      "train loss  0.118 val loss 0.310 and accuracy 0.909\n"
     ]
    }
   ],
   "source": [
    "optimizer = get_optimizer(model, lr = 0.001, wd = 1e-5)\n",
    "train_model(model, optimizer, train_dl, valid_dl, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss, valid_acc = valid_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3096579613748972, 0.9094785142172638)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loss, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.abs(valid_loss - 0.3) < 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.abs(valid_acc - 0.9) < 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
