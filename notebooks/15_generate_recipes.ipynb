{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating recipies with character-level RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Get the data from here http://www.ffts.com/recipes/lg/lg32965.zip and unzip it into data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/1000.mmf'),\n",
       " PosixPath('data/18000.mmf'),\n",
       " PosixPath('data/14000.mmf'),\n",
       " PosixPath('data/22000.mmf'),\n",
       " PosixPath('data/30000.mmf')]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = Path(\"data\")\n",
    "files = [f for f in PATH.iterdir() if str(f).endswith('.mmf')]\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMMMM----- Recipe via Meal-Master (tm) v8.05\r",
      "\r\n",
      " \r",
      "\r\n",
      "      Title: \"BE MINE\" LOLLIPOPS\r",
      "\r\n",
      " Categories: Candies, Valentine\r",
      "\r\n",
      "      Yield: 8 Servings\r",
      "\r\n",
      " \r",
      "\r\n",
      "           Text only\r",
      "\r\n",
      " \r",
      "\r\n",
      "  Source: Better Homes and Gardens, Febuary 1998 Prep time: 20 minutes\r",
      "\r\n",
      "  Cook: 6 to 8 minutes\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! head data/1000.mmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "def read_file(path):\n",
    "    with open(path, encoding=\"utf8\", errors='ignore') as f:\n",
    "        content = unidecode.unidecode(f.read())\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = read_file(\"data/1000.mmf\")\n",
    "content2 = read_file(\"data/18000.mmf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2330591"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n + n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2330591"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = content2 + content\n",
    "len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MMMMM----- Recipe via Meal-Master (tm) v8.05\\n \\n      Title: \"BE MINE\" LOLLIPOPS\\n Categories: Candies, Valentine\\n      Yield: 8 Servings\\n \\n           Text only\\n \\n  Source: Better Homes and Gardens, Febuary 1998 Prep time: 20 minutes\\n  Cook: 6 to 8 minutes\\n  \\n  2 1/2 to 3 1/2-inch round or heart-shaped metal cookie cutters 8 oz.\\n  assorted red, pink, and/or clearhard candies 35 to 60 (2 to 3 oz.)\\n  assorted small decorative candies, such as red cinnamon candies,\\n  small nonpareils, colored candy hearts, spice drops, and gumdrops\\n  Edible rose petals or other flower petals (optional) Lollipop sticks\\n  \\n  Place unwrapped hard candies in a heavy plastic bag, then place bag\\n  on top of folded towel and crush candies into small chunks wiht meat\\n  mallet or small hammer.\\n  \\n  Make only three or four lollipops at one time.  Line a baking sheet\\n  with foil.  Place desired cookie cutters on foil, at least 2 inches\\n  apart. Divide crushed candies evenly among cutters, approximately 1\\n  1/2 to 2 ta'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1226806"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "all_characters = string.printable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_characters = len(all_characters)\n",
    "n_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 48, 48, 48, 48, 74, 74, 74, 74, 74, 94, 53, 14, 12, 18, 25, 14,\n",
       "       94, 31, 18, 10, 94, 48, 14, 10, 21, 74, 48, 10, 28, 29, 14, 27, 94,\n",
       "       69, 29, 22, 70, 94, 31,  8, 75,  0,  5, 96, 94, 96, 94, 94, 94, 94,\n",
       "       94, 94, 55, 18, 29, 21, 14, 77, 94, 63, 37, 40, 94, 48, 44, 49, 40,\n",
       "       63, 94, 47, 50, 47, 47, 44, 51, 50, 51, 54, 96, 94, 38, 10, 29, 14,\n",
       "       16, 24, 27, 18, 14, 28, 77, 94, 38, 10, 23, 13, 18, 14, 28])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easy way to encode characters\n",
    "np.array([all_characters.index(c) for c in content[:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=1000\n",
    "contents = [content[i*seq_len:(i+1)*seq_len] for i in range(n//seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1226"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1226000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contents)*seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters.index(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_encoding(c):\n",
    "    if c in all_characters:\n",
    "        return all_characters.index(c)\n",
    "    else:\n",
    "        return all_characters.index(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    " class RecipeDataset(Dataset):\n",
    "    def __init__(self, path=\"data/1000.mmf\", seq_len=1000):\n",
    "        content = read_file(path) \n",
    "        n = len(content)\n",
    "        self.contents = [content[i*seq_len:(i+1)*seq_len] for i in range(n//seq_len)]\n",
    "        # shift by 1\n",
    "        self.ys = [content[i*seq_len + 1 :(i+1)*seq_len +1] for i in range(n//seq_len)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.contents)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.contents[idx]\n",
    "        y = self.ys[idx]\n",
    "        x = np.array([char_encoding(c) for c in x])\n",
    "        y = np.array([char_encoding(c) for c in y])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = RecipeDataset(files, seq_len=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([48, 48, 48, 48, 48, 74, 74, 74, 74, 74, 94, 53, 14, 12, 18, 25, 14,\n",
       "        94, 31, 18, 10, 94, 48, 14, 10, 21, 74, 48, 10, 28]),\n",
       " array([48, 48, 48, 48, 74, 74, 74, 74, 74, 94, 53, 14, 12, 18, 25, 14, 94,\n",
       "        31, 18, 10, 94, 48, 14, 10, 21, 74, 48, 10, 28, 29]))"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can start by just sending one file\n",
    "train_ds = RecipeDataset(files, seq_len=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3810"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with one-hot encoding input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeRNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, vocab_size):\n",
    "        super(RecipeRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        # code here\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        #code here\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, bash_size):\n",
    "        return torch.zeros(bash_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(all_characters)\n",
    "emb_size = 50\n",
    "hidden_size = 150\n",
    "model = RecipeRNN(emb_size, hidden_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 10000]), torch.Size([100, 10000]))"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.initHidden(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "for i in range(x.shape[1]):\n",
    "    y_t, h = model(x[:,i].long(), h)\n",
    "    loss += F.cross_entropy(y_t, y[:, i].long())\n",
    "loss /= x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.600766658782959"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that just the last x_t is used in the loss\n",
    "# update\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(all_characters)\n",
    "emb_size = 50\n",
    "hidden_size = 150\n",
    "model = RecipeRNN(emb_size, hidden_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.00001):\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, train_dl):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for x, y in train_dl:\n",
    "        batch = x.shape[0]\n",
    "        h = model.initHidden(batch)\n",
    "        loss = 0\n",
    "        x = x.long()\n",
    "        y = y.long()\n",
    "        for i in range(x.shape[1]):\n",
    "            out, h = model(x[:,i], h)\n",
    "            loss += F.cross_entropy(out, y[:, i])\n",
    "        loss /= x.shape[1]\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, lr, train_dl, epochs=20):\n",
    "    optim = get_optimizer(model, lr =lr, wd = 0.0)\n",
    "    for i in range(epochs):\n",
    "        loss = train(model, optim, train_dl)\n",
    "        if i%5 == 1: print(\"train loss %.3f\" % (loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(all_characters)\n",
    "emb_size = 50\n",
    "hidden_size = 150\n",
    "model = RecipeRNN(emb_size, hidden_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.790\n",
      "train loss 1.297\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, 0.01, train_dl,  epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.206\n",
      "train loss 1.202\n",
      "train loss 1.201\n",
      "train loss 1.200\n",
      "train loss 1.199\n",
      "train loss 1.198\n",
      "train loss 1.197\n",
      "train loss 1.197\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, 0.001, train_dl, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating recipies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = model.initHidden(1)\n",
    "inp = torch.LongTensor([all_characters.index(\"M\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1]), torch.Size([1, 150]))"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape, hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.emb(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, hidden = model(inp, hidden)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5325e-03, 5.4097e+01, 3.6071e+00, 4.1176e+00, 1.2773e+01, 1.2075e-01,\n",
       "        9.5394e+01, 5.4767e+00, 1.8936e+00, 3.1331e+00, 1.0619e+02, 1.5974e+01,\n",
       "        3.9435e-04, 4.1891e-03, 2.9012e+02, 6.6120e-02, 3.2566e+00, 2.0937e-04,\n",
       "        8.7681e-01, 2.4478e-04, 9.8413e-06, 9.7300e-03, 1.1631e+00, 8.5289e-04,\n",
       "        2.1804e+02, 1.2005e-03, 1.4019e-02, 4.6674e-02, 1.3489e-01, 9.1231e-07,\n",
       "        5.2851e-01, 4.6521e-03, 4.0609e-02, 8.0901e-02, 6.2744e-02, 9.8108e-03,\n",
       "        1.3753e+02, 7.2103e+00, 1.2496e+01, 2.2803e+01, 2.0441e+02, 2.1760e+00,\n",
       "        1.7172e+00, 4.8473e+00, 8.6792e+01, 2.7507e+00, 1.7293e+00, 1.3518e-01,\n",
       "        9.7000e+04, 2.3831e+00, 5.6466e+03, 2.5048e+01, 1.7197e+00, 1.2665e+00,\n",
       "        1.0054e+00, 1.4442e+00, 1.7010e+02, 2.3135e+00, 5.6544e+01, 1.9075e-01,\n",
       "        5.3645e+00, 1.4553e-02, 5.1243e+00, 7.8919e-01, 9.4639e-01, 3.0532e-01,\n",
       "        1.5756e-01, 1.3458e+00, 4.4846e-01, 3.6145e-02, 1.0283e+02, 4.7754e-01,\n",
       "        3.0641e-01, 8.7199e+00, 4.7178e+01, 2.9019e+01, 4.5285e+00, 8.7106e-01,\n",
       "        3.0311e+00, 2.0061e+00, 4.4589e+02, 3.7162e+02, 3.3236e-01, 8.7681e-01,\n",
       "        9.7557e+00, 8.4160e-01, 2.9653e+00, 7.2609e+00, 2.7658e+00, 8.2343e-01,\n",
       "        6.2000e-01, 6.2694e-01, 2.7373e-02, 3.9078e-01, 1.1493e+01, 6.9410e+01,\n",
       "        1.6948e+01, 4.0985e-01, 4.4633e-01, 2.2792e-01])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature=0.8\n",
    "output_dist = output.data.view(-1).div(temperature).exp()\n",
    "output_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([48])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_i = torch.multinomial(output_dist, 1)\n",
    "top_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_char = all_characters[top_i]\n",
    "predicted_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, predict_len=1000, temperature=0.8):\n",
    "    hidden = model.initHidden(1)\n",
    "    inp = torch.LongTensor([all_characters.index(\"M\")])\n",
    "    predicted = \"M\"\n",
    "    for p in range(predict_len):\n",
    "        output, hidden = model(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)\n",
    "\n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i[0]]\n",
    "        predicted += predicted_char\n",
    "        inp = top_i\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMMMCOLLIGATE CAKE\n",
      " Categories: Meats, December or for the bar (3) desired format egg and simmer 2 minutes oa the in the powder\n",
      "      1 ts Butter, sliced\n",
      "      1 c  Straw\n",
      "      1 c  Water\n",
      "      1    Lemon chopped\n",
      "           Chopped\n",
      "      1 tb Salt\n",
      "  cover container wine of heat, peppers, Indiesy. Time on the\n",
      "  spices\n",
      "      1 c  Fine\n",
      "      1 c  Milk\n",
      "    3/4 c  Sugar\n",
      "    1/2 c  Floruce cheese, minced\n",
      "      1 ts Salt\n",
      "        2 quse 1 brots to the to dough in egg bowl, way beas mixture in water in the dough is frying\n",
      "  serving seeds, Sauces to think\n",
      "      1    Egg\n",
      "      2 tb Hoy tablespoon and remaining whipped almond cheese the mago=; Mix to eashrone; garlic\n",
      "  or one quarted toie vegetables, cool balls are skillet cheese\n",
      "      2 tb Soy suttie and peel ground and stepping until with the boil. Heat the eggs each.  Makes of a can necessary sauce, turnuts & 4 sarbogeter soak\n",
      "           - juice, heaviamin\n",
      "           - \"Demoni be unbagreming that that the\n",
      "  lemon juice\n",
      "    1/4 c  Butter\n",
      "      1 \n"
     ]
    }
   ],
   "source": [
    "predicted = generate(model, predict_len=1000, temperature=0.8)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMMMM.7ASSER TRED ON THE SALAD\n",
      " Categories: Chili peeles into desired punt out granulaned holiday\n",
      "  from this corn it dish. Rollet. **TOma. [Cook and tossive out the boiling water incorpos of day almond extract\n",
      "  1 1/2 ts Sodium-Mast,\n",
      "        wittom and baking sheets with microwaves\n",
      "    1/4 c  Crushed and about 2 minutes. Serve.  Saute. Bake over mucksent almond combined Vinegar\n",
      "      1 ts Peel\n",
      "           Seasone letts a pasta\n",
      "      2 c  An the pan. Mix to boiler and seal onions and spices, green notes\n",
      "  cookies brown,\n",
      "  skin. Top will pans\n",
      "           Garlic sue befots per gring mixture.\n",
      "  \n",
      "  Cook and garlic, Indian center hands of the ingredients in for the 17 dboped\n",
      "  or raw adding.\n",
      "  \n",
      "  Diced and pan and casted ex3, or until ozzlers are sanda sliced sauce in more the paste very spread beef beef some the cheese and almond extract\n",
      "        2    Egg Nancepted and chopped hot soy.  Mix the dough of a cookie sheet of the remaining conbeding your shake blumbles\n",
      "      3 tb Chili\n",
      "      Yield:\n"
     ]
    }
   ],
   "source": [
    "predicted = generate(model, predict_len=1000, temperature=0.8)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab\n",
    "** Write the model\n",
    "** Train and generate recipes\n",
    "** Modify the dataset to include more data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "The generator is modified from this https://github.com/spro/char-rnn.pytorch/blob/282bcb6b15ab3929d6a588b455cfc0f19f32add4/generate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
