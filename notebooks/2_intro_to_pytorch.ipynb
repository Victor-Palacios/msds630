{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Intro-to-Pytorch\" data-toc-modified-id=\"Intro-to-Pytorch-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intro to Pytorch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pytorch-tensors\" data-toc-modified-id=\"Pytorch-tensors-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Pytorch tensors</a></span></li><li><span><a href=\"#Pytorch-Autograd\" data-toc-modified-id=\"Pytorch-Autograd-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Pytorch Autograd</a></span></li><li><span><a href=\"#torch.nn-module\" data-toc-modified-id=\"torch.nn-module-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>torch.nn module</a></span></li></ul></li><li><span><a href=\"#Linear-Regression-with-Pytorch\" data-toc-modified-id=\"Linear-Regression-with-Pytorch-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Linear Regression with Pytorch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gradient-Descent-with-Pytorch\" data-toc-modified-id=\"Gradient-Descent-with-Pytorch-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Gradient Descent with Pytorch</a></span></li><li><span><a href=\"#Simplified-GD-Loop\" data-toc-modified-id=\"Simplified-GD-Loop-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Simplified GD Loop</a></span><ul class=\"toc-item\"><li><span><a href=\"#Models-in-Pytorch\" data-toc-modified-id=\"Models-in-Pytorch-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Models in Pytorch</a></span></li></ul></li></ul></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#How-to-take-a-vector-back-to-numpy?\" data-toc-modified-id=\"How-to-take-a-vector-back-to-numpy?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>How to take a vector back to numpy?</a></span></li><li><span><a href=\"#Exercise:\" data-toc-modified-id=\"Exercise:-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Exercise:</a></span></li></ul></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch consists of 4 main packages:\n",
    "* torch: a general purpose array library similar to Numpy that can do computations on GPU\n",
    "* torch.autograd: a package for automatically obtaining gradients\n",
    "* torch.nn: a neural net library with common layers and cost functions\n",
    "* torch.optim: an optimization package with common optimization algorithms like SGD, Adam, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch tensors\n",
    "Like Numpy tensors but can utilize GPUs to accelerate its numerical computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tensors from lists or numpy arrays\n",
    "x = torch.tensor([[1, 2],[3, 4]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random tensor\n",
    "N = 5\n",
    "x = torch.randn(N, 10).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0065, -1.3105,  0.5226,  2.2072, -0.5752, -1.1019,  1.0525,  0.8034,\n",
       "          1.1506, -0.5822],\n",
       "        [-0.4955, -0.1096, -0.5349, -0.3082, -0.2941,  1.2675,  0.9798,  1.0569,\n",
       "         -1.5108, -0.5627],\n",
       "        [-1.1474,  1.5807, -0.7938,  0.9268, -0.8612,  2.2317, -0.0980, -1.7573,\n",
       "          2.3066,  1.0729],\n",
       "        [ 0.6293, -0.9167,  0.8247,  1.5185, -0.3005, -0.2514,  1.1836,  0.6375,\n",
       "          0.5082,  0.1519],\n",
       "        [ 0.7071, -0.0634, -0.8860, -1.2036, -0.3730,  0.9233,  0.7118,  1.4800,\n",
       "         -0.0972, -0.1401]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0065, -1.3105,  0.5226,  2.2072, -0.5752, -1.1019,  1.0525,  0.8034,\n",
       "          1.1506, -0.5822, -0.4955, -0.1096, -0.5349, -0.3082, -0.2941,  1.2675,\n",
       "          0.9798,  1.0569, -1.5108, -0.5627, -1.1474,  1.5807, -0.7938,  0.9268,\n",
       "         -0.8612,  2.2317, -0.0980, -1.7573,  2.3066,  1.0729,  0.6293, -0.9167,\n",
       "          0.8247,  1.5185, -0.3005, -0.2514,  1.1836,  0.6375,  0.5082,  0.1519,\n",
       "          0.7071, -0.0634, -0.8860, -1.2036, -0.3730,  0.9233,  0.7118,  1.4800,\n",
       "         -0.0972, -0.1401]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping of tensors using .view()\n",
    "x.view(1,-1) #-1 makes torch infer the second dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Autograd\n",
    "The autograd package in PyTorch provides classes and functions implementing automatic differentiation of arbitrary scalar valued function. For example, the gradient of the error with respect to all parameters.\n",
    "\n",
    "In order for this to happen we need to declare our paramerers as Tensors with the requires_grad=True keyword. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3., 4., 5., 6.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  9., 19., 33., 51., 73.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*x**2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(188., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = (2*x**2 +1).sum()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.backward() # computes the grad of L with respect to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.,  8., 12., 16., 20., 24.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7605,  1.9789, -1.1921],\n",
       "        [-0.7827, -0.1883, -1.4586]], requires_grad=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is another example\n",
    "x = torch.randn(2, 3)\n",
    "x.requires_grad = True\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.6910, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = (x**2).sum()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5211,  3.9578, -2.3842],\n",
       "        [-1.5653, -0.3766, -2.9171]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.backward()\n",
    "x.grad # note, it is the same shape as x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn module\n",
    "A neural net library with common layers and cost functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Linear(5, 3)` creates a linear transformation ($A\\cdot X+b$) of a $N \\times 5$ matrix into a $N \\times 3$ matrix, where N can be anything (number of observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5 # number of input featutes\n",
    "M = 3 # neurons in the first hidden layer\n",
    "linear_map = nn.Linear(D, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.1198, -0.0453, -0.2542, -0.0780,  0.3376],\n",
       "         [ 0.1268, -0.0038, -0.4344,  0.0947,  0.3005],\n",
       "         [-0.1481,  0.2717,  0.2109, -0.3708, -0.0754]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4226, -0.3958, -0.4254], requires_grad=True)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters are initialized randomly\n",
    "[p for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([3, 5]), torch.Size([3])]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Linear Regression with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of linear regression is to fit a line to a set of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_fake_data(n, a, b):\n",
    "    x = np.random.uniform(0,1,n) \n",
    "    y = lin(a,b,x) + 0.1 * np.random.normal(0,3,n)\n",
    "    return x, y\n",
    "\n",
    "x, y = gen_fake_data(50, 3., 8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWDElEQVR4nO3dcaxkZ33e8e/jtQl2TIvNLmBsbtaO3BQXlcq5NoYS5MRRaq8suSAQJmmhFmVFioFGaotVtYDapoUqfySBFGsDlrGi2BDjhA1xAIsoGERM99rBZo1F2SxmvdiwCyagjY3wwq9/3LFyPZy7O3fvnDPnzHw/0uremXnv3N+7uzrPnPc973tSVUiSNO6kWRcgSeonA0KS1MiAkCQ1MiAkSY0MCElSo5NnXcA0bd26tbZv3z7rMiRpMO6+++5vV9W2ptfmKiC2b9/OysrKrMuQpMFI8vX1XnOISZLUyICQJDUyICRJjQwISVIjA0KS1MiAkCQ1MiAkaUD2Hz7Ch/ccYP/hI63/rrlaByFJ82z/4SNc+d7PUQUJfPwtL+O8bae39vs8g5Ckgdjz4KNUweNP/Iiq1cdtMiAkaSAu2n4mCZx6yhaS1cdtcohJkgbivG2n8/G3vIw9Dz7KRdvPbHV4CQwISRqU87ad3nowPMkhJklSIwNCkqaky0tQu9BaQCS5IcmhJHvXPPfqJPcn+XGS5WP87OVJvpJkX5Lr2qpRkqblyUtQ37X7y1z53s/NRUi0eQZxI3D52HN7gVcCd673Q0m2AL8HXAFcALw2yQUt1ShJU9H1JahdaC0gqupO4NGx5x6oqq8c50cvBvZV1f6q+iFwC3BVS2VK0lR0fQlqF/p4FdPZwENrHh8EXrxe4yQ7gZ0AS0tL7VYmSevo+hLULvQxINLwXK3XuKp2AbsAlpeX120nSW07kUtQ9x8+0ttQ6WNAHASev+bxOcDDM6pFklrT9d5KG9XHy1z3AOcnOTfJ04Crgd0zrkmSpq7vE9ttXuZ6M/BXwM8lOZjkDUlekeQg8BLgz5J8ctT2eUluB6iqo8C1wCeBB4CPVNX9bdUpSbPS94ntVM3PsP3y8nKtrKzMugxJmtis5yCS3F1VjevS+jgHIUmDN+mBf9KJ7fXer82AMSAkacqmPfm83vu1Pcndx0lqSRq0aU8+r/d+bU9yGxCSFt60N9mb9uTzeu/X9iS3k9SSFlpbwzTTnhtoaw7CSWpJWsfaYZpTT9nCngcfPe6BdpKD8rRv7LPe+7V5AyEDQtJC2+gwTd9XP0+TASFpoW10k70TOeMYKgNC0sLbyDBN31c/T5MBIUkbMI/beq/HgJCkDWpzYrhPXAchSWpkQEiSGhkQkqRGBoSkhTDt7TQWgZPUkubeIi1umybPICTNvb7f2rOvDAhJc2+RFrdNk0NMkubeIi1umyYDQtJCWJTFbdPU2hBTkhuSHEqyd81zZya5I8lXR1/PWOdnH0zypSRfTOINHiRpBtqcg7gRuHzsueuAT1fV+cCnR4/X84tV9c/Wu5GFJKldrQVEVd0JjF8qcBXwodH3HwL+ZVu/X5K0OV1fxfScqnoEYPT12eu0K+BTSe5OsvNYb5hkZ5KVJCuHDx+ecrmStLj6epnrP6+qC4ErgDcnefl6DatqV1UtV9Xytm3buqtQkuZc1wHxrSRnAYy+HmpqVFUPj74eAv4YuLizCiVJQPcBsRt4/ej71wMfG2+Q5KeTPOPJ74FfAfaOt5Mk91dqV2vrIJLcDFwKbE1yEHgn8G7gI0neABwAXj1q+zzgA1W1A3gO8MdJnqzvD6vqE23VKWnV/sNHBrWQzP2V2tdaQFTVa9d56bKGtg8DO0bf7wde1FZdkn7SEA+2a/dXOvWULex58NHOah5amJ4oV1JL6vRgu9GD63rtZ7W/0hDD9EQZEJI6O9hu9OB6rPaz2l9plmcuXTMgJHV2sN3owfV47Wexv9Ii7QxrQEg919V4dxcH240eXPt4MF6knWFTVbOuYWqWl5drZcW9/TQ/pj3e3YfJ1WnNQWg6kty93p53nkFIPTbN8e6+TK5u9EzFbbpnp69bbUhiukMs3nZTG+UZhNRj0xzv7uN4vvrNgJB6blpDLIs0uarpMCCkBeJ4vjbCOQhJUiMDQpLUyICQJDUyICRJjQwISVIjA0KS1MiAkCQ1MiAkSY0MCElSIwNCktbYf/gIH95zgP2Hj8y6lJlrLSCS3JDkUJK9a547M8kdSb46+nrGOj97eZKvJNmX5Lq2apSktZ7cEv1du7/Mle/93MKHRJtnEDcCl489dx3w6ao6H/j06PFTJNkC/B5wBXAB8NokF7RYpzRVfgIdLrdEf6rWNuurqjuTbB97+irg0tH3HwL+Enj7WJuLgX1VtR8gyS2jn/tyS6VKU9OXm/I01eUursfnluhP1fVurs+pqkcAquqRJM9uaHM28NCaxweBF6/3hkl2AjsBlpaWpliqtHHTvAPctPQ1tPrILdGfqo/bfafhuXVvnF1Vu4BdsHpP6raKkibRx0+gfQytPnNL9L/XdUB8K8lZo7OHs4BDDW0OAs9f8/gc4OFOqpM2qY+fQPsYWhqGrgNiN/B64N2jrx9raLMHOD/JucA3gKuBX+2sQmmT+vYJtI+hpWFoLSCS3MzqhPTWJAeBd7IaDB9J8gbgAPDqUdvnAR+oqh1VdTTJtcAngS3ADVV1f1t1Sougb6GlYWjzKqbXrvPSZQ1tHwZ2rHl8O3B7S6VJkibgSmpJUiMDQuoRF9mpT/p4mau0kFyvoL7xDELqic1s8+CZh9rgGYTUEye6XsEzD7XFgJB64kTXK7hSWm0xIKQeOZH1Cq6UVlsMCGlgxndmdaW02mJASAOy3nyDK6XVBq9ikgbEG9qoSwaENCDON6hLDjFJA+J8g7pkQEgD43yDuuIQkySpkQEhbYJbXGieOcQknaAhbXExvnZCmoQBIZ2goWxxMaQgU784xCSdoKFccuraCZ0ozyCkEzSUS06HEmTqHwNC2oQhXHI6jSBzDmMxzSQgkrwNeCMQ4Per6rfHXr8U+BjwtdFTt1XVf+u0SGmD+nwQ3UyQOYexuDoPiCQvZDUcLgZ+CHwiyZ9V1VfHmn62qq7suj7pRMzzQXQok/GavllMUr8AuKuqHquqo8BngFfMoA5patqYCO7LGgvnMBbXLIaY9gK/meRZwOPADmClod1LktwLPAz8h6q6v+nNkuwEdgIsLS21U7F0HNM+iPbpjGQok/Gavs4DoqoeSPIe4A7gCHAvcHSs2T3Az1TVkSQ7gD8Bzl/n/XYBuwCWl5ertcKlY5j2QbRvwzpDmIzX9B13iCnJtUnOmOYvraoPVtWFVfVy4FHgq2Ovf7+qjoy+vx04JcnWadYgTdt5207nNRctTeVA6rCO+mCSM4jnAnuS3APcAHyyqjb1ST3Js6vqUJIl4JXAS8Zefy7wraqqJBezGmTf2czvlIbEYR31wXEDoqr+S5L/CvwKcA3wviQfAT5YVX9zgr/3o6M5iCeAN1fVd5O8afT7rgdeBfx6kqOszlNcvdlQkobGYR3N2kRzEKNP8t8EvsnqfMEZwK1J7qiq/7TRX1pVv9Dw3PVrvn8f8L6Nvq/mV5/XGEjz6rgBkeStwOuBbwMfAP5jVT2R5CRW5w42HBDSRnzmK4d4400rJGHLSZmrNQZSn01yBrEVeGVVfX3tk1X14yQuZFOr9h8+whtvupsf/qiA4qdOPmnmV/RIi2KSOYh3HOO1B6ZbjvRUex58lOTvH1eVV/RIHXGzPvXaRdvPZMtJ4adOPokq+P3X/bxnD1JHDAj1mpd7SrNjQKj31l7u6dVMUncMCA1Gn/YnmpSBpiEzIDQYfduf6HiGGGjSWt6TWsfUly2nYXj7E3kvaA2dZxBaV98+AQ9twnpogSaNMyC0rj4O6Qxpf6KhBZo0zoDQuob+CbgPE8RDCjRpnAGhdQ35E3DfhsekITIgdExD+gS89oyhj8Nj0tAYEJoL42cM7/+1Cwc9PCb1gQGhuTB+xvDN7/9gsMNjUl8YEJoLTRPqQxoek/rIgNBcGPKEutRXrqReQH1aHT1N5207nddctAQws/7N69+tFpNnEAtms5d/9mFtwbHM8vJWL63VvJnJGUSStyXZm+T+JP++4fUk+d0k+5Lcl+TCWdQ5jzazP9CTB8B37f4yV773c738lDzL/Y/ce0nzpvOASPJC4I3AxcCLgCuTnD/W7Arg/NGfncD7Oy1yjm1mdfQQDoCzXP099JXn0rhZDDG9ALirqh4DSPIZ4BXA/17T5irgpqoq4K4kz0xyVlU90n25/TGN4Z3NTOYO4QA4y8lqJ8o1b2YREHuB30zyLOBxYAewMtbmbOChNY8Pjp77iYBIspPVswyWlpbaqLcXpjm+faKXfw7lADjLy1u9tFbzpPMhpqp6AHgPcAfwCeBe4OhYszT96Drvt6uqlqtqedu2bVOttU/6MrzThyuFJHVjJlcxVdUHgQ8CJPmfrJ4hrHUQeP6ax+cAD3dTXT/1aXjHq3WkxTCTgEjy7Ko6lGQJeCXwkrEmu4Frk9wCvBj43qLPP/RpeMeN8KTFMKt1EB8dzUE8Aby5qr6b5E0AVXU9cDurcxP7gMeAa2ZUZ6/0ZXy7T2czktqT1QuF5sPy8nKtrIzPd6sNfV8wJ2kySe6uquWm11xJrRPSl7MZSe1xLyZJUiMDQpLUyIDQprh7qTS/nIOYU11MIrseQppvBsQc6urA7XoIab45xDSHutqWw/UQ0nzzDGIOdXXg7tPqbknTZ0DMoS4P3K6HkOaXATGnPHBL2iznICRJjQyIOeBaBEltcIhp4FyLIKktnkEMXF/uNCdp/hgQA+daBEltcYhp4FyLIKktBsQc8JJWSW1wiEmS1MiAkCQ1MiAkSY1mEhBJfiPJ/Un2Jrk5ydPHXr80yfeSfHH05x2zqLNrLniT1CedT1InORt4K3BBVT2e5CPA1cCNY00/W1VXdl3frLjgTVLfzGqI6WTg1CQnA6cBD8+ojt5wwZukvuk8IKrqG8BvAQeAR4DvVdWnGpq+JMm9Sf48yT9Z7/2S7EyykmTl8OHDLVXdPhe8SeqbVFW3vzA5A/go8Brgb4E/Am6tqj9Y0+YfAD+uqiNJdgC/U1XnH++9l5eXa2VlpaXK29fFfaQlaa0kd1fVctNrsxhi+mXga1V1uKqeAG4DXrq2QVV9v6qOjL6/HTglydbuS+3WedtO5zUXLRkOknphFgFxALgkyWlJAlwGPLC2QZLnjl4jycWs1vmdziuVpAXW+VVMVfWFJLcC9wBHgb8GdiV50+j164FXAb+e5CjwOHB1dT0WJkkLrvM5iDYNfQ5CkrrWtzkISdIAGBCSpEYGhCSpkQEhSWpkQEiSGhkQkqRGBkRH3Mpb0tB4T+oOuJW3pCHyDKIDbuUtaYgMiA64lbekIXKIqQPnbTudj7/lZW7lLWlQDIiOnLftdINB0qA4xCRJamRASJIaGRDHsZH1C651kDRPnIM4ho2sX3Ctg6R54xnEMWxk/YJrHSTNGwPiGDayfsG1DpLmjbccPY79h49MvH5hI20lqQ+OdctR5yCO41jrF8YDwbUOkubJTAIiyW8A/xYo4EvANVX1gzWvB/gdYAfwGPBvquqeWdS6HielJc27zucgkpwNvBVYrqoXAluAq8eaXQGcP/qzE3h/p0VOwElpSfNuVpPUJwOnJjkZOA14eOz1q4CbatVdwDOTnNV1kcfipLSkedf5EFNVfSPJbwEHgMeBT1XVp8aanQ08tObxwdFzj4y/X5KdrJ5lsLS0dEI1ncjkshvwSZp3nQdEkjNYPUM4F/hb4I+S/Kuq+oO1zRp+tPFyq6raBeyC1auYNlrPZuYSnJSWNM9mMcT0y8DXqupwVT0B3Aa8dKzNQeD5ax6fw08OQ02FcwmS1GwWAXEAuCTJaaOrlS4DHhhrsxt4XVZdAnyvqn5ieGkanEuQpGazmIP4QpJbgXuAo8BfA7uSvGn0+vXA7axe4rqP1ctcr2mrHucSJKmZK6klaYEdayW1ezFJkhoZEJKkRgaEJKmRASFJamRASJIaGRCSpEYGhCSpkQExBfsPH+HDew6w//CRWZciSVPjHeU2yRsHSZpXnkFskpv9SZpXBsQmudmfpHnlENMmudmfpHllQEyBNw6SNI8cYpIkNTIgJEmNDAhJUiMDQpLUyICQJDUyICRJjebqntRJDgNfHz3cCnx7huXM2iL3f5H7Dovdf/u+cT9TVduaXpirgFgrycp6N+JeBIvc/0XuOyx2/+37dPvuEJMkqZEBIUlqNM8BsWvWBczYIvd/kfsOi91/+z5FczsHIUnanHk+g5AkbYIBIUlqNPiASHJ5kq8k2ZfkuobXk+R3R6/fl+TCWdTZhgn6/mujPt+X5PNJXjSLOttyvP6vaXdRkh8leVWX9bVpkr4nuTTJF5Pcn+QzXdfYpgn+7//DJH+a5N5R/6+ZRZ3TluSGJIeS7F3n9eke76pqsH+ALcDfAOcBTwPuBS4Ya7MD+HMgwCXAF2Zdd4d9fylwxuj7K+al75P2f027vwBuB14167o7/Ld/JvBlYGn0+Nmzrrvj/v9n4D2j77cBjwJPm3XtU+j7y4ELgb3rvD7V493QzyAuBvZV1f6q+iFwC3DVWJurgJtq1V3AM5Oc1XWhLThu36vq81X13dHDu4BzOq6xTZP82wO8BfgocKjL4lo2Sd9/Fbitqg4AVNWi9b+AZyQJcDqrAXG02zKnr6ruZLUv65nq8W7oAXE28NCaxwdHz220zRBttF9vYPWTxbw4bv+TnA28Ari+w7q6MMm//T8Czkjyl0nuTvK6zqpr3yT9fx/wAuBh4EvA26rqx92UN1NTPd4N/ZajaXhu/LrdSdoM0cT9SvKLrAbEy1qtqFuT9P+3gbdX1Y9WP0jOjUn6fjLw88BlwKnAXyW5q6r+X9vFdWCS/v8L4IvALwE/C9yR5LNV9f22i5uxqR7vhh4QB4Hnr3l8DqufGDbaZogm6leSfwp8ALiiqr7TUW1dmKT/y8Ato3DYCuxIcrSq/qSbElsz6f/7b1fV3wF/l+RO4EXAPATEJP2/Bnh3rQ7M70vyNeAfA/+3mxJnZqrHu6EPMe0Bzk9ybpKnAVcDu8fa7AZeN5rdvwT4XlU90nWhLThu35MsAbcB/3pOPjmuddz+V9W5VbW9qrYDtwL/bg7CASb7f/8x4BeSnJzkNODFwAMd19mWSfp/gNWzJ5I8B/g5YH+nVc7GVI93gz6DqKqjSa4FPsnqlQ03VNX9Sd40ev16Vq9e2QHsAx5j9ZPF4E3Y93cAzwL+z+hT9NGak50uJ+z/XJqk71X1QJJPAPcBPwY+UFWNl0YOzYT/9v8duDHJl1gddnl7VQ1+G/AkNwOXAluTHATeCZwC7Rzv3GpDktRo6ENMkqSWGBCSpEYGhCSpkQEhSWpkQEiSGhkQkqRGBoQkqZEBIbVkdB+K+5I8PclPj+5L8MJZ1yVNyoVyUouS/A/g6axumHewqv7XjEuSJmZASC0a7RW0B/gB8NKq+tGMS5Im5hCT1K4zWb1hzTNYPZOQBsMzCKlFSXazesezc4GzquraGZckTWzQu7lKfTa6i9vRqvrDJFuAzyf5par6i1nXJk3CMwhJUiPnICRJjQwISVIjA0KS1MiAkCQ1MiAkSY0MCElSIwNCktTo/wN2kjck0OLFkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x,y, s=8); plt.xlabel(\"x\"); plt.ylabel(\"y\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to find **parameters** (weights) $a$ and $b$ such that you minimize the *error* between the points and the line $a\\cdot x + b$. Note that here $a$ and $b$ are unknown. For a regression problem the most common *error function* or *loss function* is the **mean squared error** ($\\sum_i (\\hat{y}_i - y_i)^2$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_hat, y): return ((y_hat - y) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we believe $a = 10$ and $b = 5$ then we can compute `y_hat` which is our *prediction* and then compute our error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.315993750135441"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = lin(10,5,x)\n",
    "mse(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(a, b, x, y): return mse(lin(a,b,x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.315993750135441"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss(10, 5, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have specified the *model* (linear regression) and the *evaluation criteria* (or *loss function*). Now we need to handle *optimization*; that is, how do we find the best values for $a$ and $b$? How do we find the best *fitting* linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a fixed dataset $x$ and $y$ `mse_loss(a,b)` is a function of $a$ and $b$. We would like to find the values of $a$ and $b$ that minimize that function.\n",
    "\n",
    "**Gradient descent** is an algorithm that minimizes functions. Given a function defined by a set of parameters, gradient descent starts with an initial set of parameter values and iteratively moves toward a set of parameter values that minimize the function. This iterative minimization is achieved by taking steps in the negative direction of the function gradient.\n",
    "\n",
    "Here is gradient descent implemented in [PyTorch](http://pytorch.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000,))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate some more data\n",
    "x, y = gen_fake_data(10000, 3., 8.)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap x and y as tensor \n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9858], dtype=torch.float64, requires_grad=True),\n",
       " tensor([1.4596], dtype=torch.float64, requires_grad=True))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random Tensors for weights, and wrap them in tensors.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these tensors during the backward pass.\n",
    "a, b = np.random.randn(1), np.random.randn(1)\n",
    "a = torch.tensor(a, requires_grad=True)\n",
    "b = torch.tensor(b, requires_grad=True)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.410181931250335\n",
      "0.5297583258938735\n",
      "0.15683268693929575\n",
      "0.1398169861492861\n",
      "0.12839956882141362\n",
      "0.11962190508633316\n",
      "0.1128657048364274\n",
      "0.10766538288263548\n",
      "0.10366263732914219\n",
      "0.10058167962722271\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    loss = mse_loss(a,b,x,y)\n",
    "    if t % 1000 == 0: print(loss.item())\n",
    "    \n",
    "    # Computes the gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this call a.grad and b.grad will be Variables holding the gradient\n",
    "    # of the loss with respect to a and b respectively\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update a and b using gradient descent; a.data and b.data are Tensors,\n",
    "    # a.grad and b.grad are Variables and a.grad.data and b.grad.data are Tensors\n",
    "    a.data -= learning_rate * a.grad.data\n",
    "    b.data -= learning_rate * b.grad.data\n",
    "    \n",
    "    # Zero the gradients\n",
    "    a.grad.data.zero_()\n",
    "    b.grad.data.zero_()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.3293], dtype=torch.float64, requires_grad=True) tensor([7.8235], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified GD Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear tranformation with input dimension=1 and output dimension=1\n",
    "nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple way of specifying a linear regression model\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(1, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent way of specifiying the same model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        return x \n",
    "model =  LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.6001]], requires_grad=True), Parameter containing:\n",
      "tensor([0.1698], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# note here we have just two parameters, why?\n",
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = gen_fake_data(10000, 3., 8.)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you have to be careful with the dimensions that your model is expecting\n",
    "x = torch.unsqueeze(x, 1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2879],\n",
      "        [-0.0557],\n",
      "        [-0.3359],\n",
      "        ...,\n",
      "        [-0.0240],\n",
      "        [-0.0311],\n",
      "        [ 0.1233]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "y_hat = model(x)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(94.0537, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.unsqueeze(1)\n",
    "F.mse_loss(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data\n",
    "x_val, y_val = gen_fake_data(1000, 3., 8.)\n",
    "x_val = torch.tensor(x_val).float().unsqueeze(1)\n",
    "y_val = torch.tensor(y_val).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optim package to define an Optimizer that will update the \n",
    "# weights of\n",
    "# the model for us. Here we will use Adam\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 94.054 valid loss 89.670\n",
      "train loss 0.108 valid loss 0.106\n",
      "train loss 0.094 valid loss 0.091\n",
      "train loss 0.091 valid loss 0.088\n",
      "train loss 0.090 valid loss 0.087\n",
      "train loss 0.089 valid loss 0.087\n",
      "train loss 0.089 valid loss 0.087\n",
      "train loss 0.089 valid loss 0.087\n",
      "train loss 0.089 valid loss 0.087\n",
      "train loss 0.089 valid loss 0.087\n"
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    model.train() # some layers have different behavior during train/and evaluation\n",
    "    y_hat = model(x)\n",
    "    loss = F.mse_loss(y_hat, y)\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # checking validation loss\n",
    "    model.eval()  # some layers have different behavior during train/and evaluation\n",
    "    y_hat_val = model(x_val)\n",
    "    val_loss = F.mse_loss(y_hat_val, y_val)\n",
    "    \n",
    "    if t % 1000 == 0: print(\"train loss %.3f valid loss %.3f\" % (loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[2.9973]], requires_grad=True), Parameter containing:\n",
      "tensor([8.0045], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating fake data\n",
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_logistic_fake_data(n, a, b):\n",
    "    x = np.random.uniform(-20,20, (n, 2))\n",
    "    x2_hat = lin(a,b, x[:,0])\n",
    "    y = x[:,1] > x2_hat\n",
    "    return x, y.astype(int)\n",
    "\n",
    "x, y = gen_logistic_fake_data(100, 1., 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f99b81605b0>]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.arange(-20, 20, 0.2)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x[:,0],x[:,1],c=y, s=8);\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\");\n",
    "plt.plot(t, t + 0.5, 'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating train and val data\n",
    "x, y = gen_logistic_fake_data(10000, 1., 0.5)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float().unsqueeze(1)\n",
    "\n",
    "x_val, y_val = gen_logistic_fake_data(1000, 1., 0.5)\n",
    "x_val = torch.tensor(x_val).float()\n",
    "y_val = torch.tensor(y_val).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.380 valid loss 0.161\n",
      "train loss 0.015 valid loss 0.015\n",
      "train loss 0.012 valid loss 0.011\n",
      "train loss 0.010 valid loss 0.009\n",
      "train loss 0.008 valid loss 0.007\n",
      "train loss 0.007 valid loss 0.006\n",
      "train loss 0.006 valid loss 0.005\n",
      "train loss 0.005 valid loss 0.003\n",
      "train loss 0.004 valid loss 0.003\n",
      "train loss 0.004 valid loss 0.002\n"
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    model.train()\n",
    "    y_hat = model(x)\n",
    "    loss = F.binary_cross_entropy(torch.sigmoid(y_hat), y)\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat_val = model(x_val)\n",
    "    val_loss = F.binary_cross_entropy(torch.sigmoid(y_hat_val), y_val)\n",
    "    \n",
    "    if t % 1000 == 0: print(\"train loss %.3f valid loss %.3f\" % (loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-10.8642,  10.8753]], requires_grad=True), Parameter containing:\n",
      "tensor([-5.6112], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to take a vector back to numpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = gen_logistic_fake_data(10, 1., 0.5)\n",
    "x = torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2.3072705,  10.760361 ],\n",
       "       [ 17.629942 ,  19.735785 ],\n",
       "       [-15.760689 ,  -8.301015 ],\n",
       "       [-19.339895 ,  19.83385  ],\n",
       "       [  5.6111574,   6.8750906],\n",
       "       [ 17.921926 ,  14.214071 ],\n",
       "       [  6.9259534,   8.435971 ],\n",
       "       [ -9.074593 ,  -1.0895311],\n",
       "       [  9.3212385,  16.342587 ],\n",
       "       [ 15.396296 ,   7.0311146]], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "Compute the accuracy of the validation logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need more?\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/intro.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References\n",
    "* https://pytorch.org/docs/stable/index.html\n",
    "* http://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "* https://hsaghir.github.io/data_science/pytorch_starter/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "116px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
